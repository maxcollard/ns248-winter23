{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "827f6e17-0703-45bd-ba0c-ab3303f686de",
   "metadata": {},
   "source": [
    "# Problem Set 1\n",
    "## UCSF NS248, Winter 2023\n",
    "\n",
    "### Solution notes by Max Collard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6934047d-a2ad-497d-918c-b0fd15094480",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8557b411-f8f4-48e0-acab-de61cc0bda53",
   "metadata": {},
   "source": [
    "## Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6615bdb0-3c39-431f-a039-28c3483542cc",
   "metadata": {},
   "source": [
    "In my notation, I will say that:\n",
    "\n",
    "#### Sets\n",
    "* $\\Omega$ is the **sample space**, containing every possible universe we could be living in\n",
    "* $A \\subseteq \\Omega$ means that $A$ is a **subset** of $\\Omega$ (note that $\\Omega$ is a subset of $\\omega$, hence the equals sign)\n",
    "* $A \\subsetneq \\Omega$ means that $A$ is a **strict subset** of $\\Omega$ (in particular meaning that $A \\neq \\Omega$)\n",
    "* $\\omega \\in \\Omega$ means that the outcome $\\omega$ is **an element of $\\Omega$**, meaning that it is one possible universe\n",
    "* $\\emptyset$ is the **empty set**, which has nothing in it\n",
    "* $A^c$, the **complement** of $A$, meaning everything in $\\Omega$ *except* for $A$\n",
    "* $A \\cup B$, $A$ **union** $B$, is the set of outcomes in *either* $A$ or $B$\n",
    "    * $\\bigcup_i A_i$ means \"the set of outcomes in any of the $A_i$\"\n",
    "* $A \\cap B$, $A$ **intersect** $B$, is the set of outcomes in *both* $A$ and $B$\n",
    "    * $\\bigcap_i A_i$ means \"the set of outcomes in every one of the $A_i$\"\n",
    "\n",
    "#### Functions\n",
    "* $f: X \\to Y$ means that $f$ is a function that takes an input value from the set $X$ and produces some output value in the set $Y$\n",
    "* $f: x \\mapsto y$ is an alternate notation that means that $f$ takes each input value $x$ and maps it to the output value $y$\n",
    "\n",
    "#### Probability\n",
    "* $\\operatorname{Pr}(A)$ is the **probability** of the set $A$, meaning its *size* inside of the multiverse $\\Omega$\n",
    "* $\\operatorname{Pr}(A \\mid B)$ is the **conditional probability** of $A$ **given** $B$, meaning the *relative* size of $A$ inside of $B$\n",
    "* If $V$ is a $X$-valued **random variable**, then $(V = x) \\subseteq \\Omega$ is the set of all outcomes in $\\Omega$ where $V$ takes the value $x$. It is the set of all universes in which we see the observation $V$ take the value $x$.\n",
    "    * This lets us meaningful talk about things like $\\operatorname{Pr}(V = x)$ on the same footing as everything else.\n",
    "    * That is, thinking of $V$ as a way of assigning a value in $X$ to every possible outcome in $\\Omega$ (that is, $V$ is a *function* $V: \\Omega \\to X$), then\n",
    "    $$ (V = x) = V^{-1}(x) $$\n",
    "        i.e., the inverse image of $x$.\n",
    "    > *N.B.*: For those who have seen measure theory, this is why a \"measurable function\" is defined as preserving measurability under inverse image: it guarantees that we can always take the probability (size) of the set ($V = x$) for any $x$, which is needed for the theory to talk about anything we care about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cb7aee-6776-4acf-87a9-5e8912191bb0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3daa93-2692-4849-893b-0e482b7ec545",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec2c735-f3ad-4012-9205-10dc22d528dc",
   "metadata": {},
   "source": [
    "### Complements\n",
    "\n",
    "Probability is a measure of **size**. It is built mathematically in order to preserve our intuition about the way size works. Most notably, the size of two non-overlapping objects $A$ and $B$ **add**:\n",
    "\n",
    "$$ A \\cap B = \\emptyset \\Leftrightarrow \\operatorname{Pr}(A \\cap B) = \\operatorname{Pr}(A) + \\operatorname{Pr}(B) $$\n",
    "\n",
    "It also assumes that probability is **normalized**—that is, the entire multiverse is a finite size:\n",
    "\n",
    "$$ \\operatorname{Pr}(\\Omega) = 1 $$\n",
    "\n",
    "Since $A \\cup A^c = \\Omega$, we note that\n",
    "\n",
    "$$ \\operatorname{Pr}(A \\cup A^c) = \\operatorname{Pr}(\\Omega) = 1 $$\n",
    "\n",
    "Since $A$ and $A^c$ do not overlap, this means that\n",
    "\n",
    "$$ \\operatorname{Pr}(A) + \\operatorname{Pr}(A^c) = 1 $$\n",
    "\n",
    "i.e., the intuition that $\\operatorname{Pr}(A^c) = 1 - \\operatorname{Pr}(A)$. This fact follows directly from our assumptions that probability behaves like physical size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1fe6f5-b16a-43e6-88cd-76780d0d2c59",
   "metadata": {},
   "source": [
    "### Independence\n",
    "\n",
    "Probability is a measure of **size**. It is built mathematically in order to preserve our intuition about the way size works. Most notably, the size of two non-overlapping objects $A$ and $B$ **add**:\n",
    "\n",
    "$$ A \\cap B = \\emptyset \\Leftrightarrow \\operatorname{Pr}(A \\cap B) = \\operatorname{Pr}(A) + \\operatorname{Pr}(B) $$\n",
    "\n",
    "Conditional probability is a measure of **relative size**. That is, the probability of $A$ conditioned on (given) $B$ is just the size of the part of a $A$ inside of $B$, relative to the total size of $B$:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "    \\operatorname{Pr}(A \\mid B) & = & \\frac{\\operatorname{Pr}(A \\cap B)}{\\operatorname{Pr}(B)} \\\\\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "One can think of this as what would happen to our understanding of $A$ if we *knew* that $B$ was true. It is often convenient to assume that knowing $B$ *has no effect whatsoever* on our understanding of $A$, i.e.,\n",
    "\n",
    "$$ \\operatorname{Pr}(A \\mid B) = \\operatorname{Pr}(A) $$\n",
    "\n",
    "If this is true, we say that $A$ is **independent** of $B$. This means in particular that\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "    \\operatorname{Pr}(A) & = & \\frac{\\operatorname{Pr}(A \\cap B)}{\\operatorname{Pr}(B)} \\\\\n",
    "    \\operatorname{Pr}(A)\\,\\operatorname{Pr}(B) & = & \\operatorname{Pr}(A \\cap B)\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "(This is taken as the definition of independence in most textbooks, because conditional probability has some hairy technical considerations when $\\operatorname{Pr}(B) = 0$.)\n",
    "\n",
    "Note that this is true even if we start in the other direction, with\n",
    "\n",
    "$$ \\operatorname{Pr}(B \\mid A) = \\operatorname{Pr}(B) $$\n",
    "\n",
    "This implies the same outcome:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "    \\operatorname{Pr}(B \\mid A) = \\operatorname{Pr}(B) & = & \\frac{\\operatorname{Pr}(A \\cap B)}{\\operatorname{Pr}(A)} \\\\\n",
    "    \\operatorname{Pr}(B)\\,\\operatorname{Pr}(A) & = & \\operatorname{Pr}(A \\cap B)\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "So independence is **symmetric**, i.e., not directed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d515f807-3d82-43eb-9b18-460d3e920015",
   "metadata": {},
   "source": [
    "### Bayes' Rule\n",
    "\n",
    "Recall that the probability of $A$ conditioned on (given) $B$ is just the size of $A$ inside of $B$, relative to the total size of $B$:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "    \\operatorname{Pr}(A \\mid B) & = & \\frac{\\operatorname{Pr}(A \\cap B)}{\\operatorname{Pr}(B)} \\\\\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Going theo ther way, we have that\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "    \\operatorname{Pr}(B \\mid A) & = & \\frac{\\operatorname{Pr}(A \\cap B)}{\\operatorname{Pr}(A)} \\\\\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "There is a symmetry in this definition, as we can solve for $\\operatorname{Pr}(A \\cap B)$ in either case:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "    \\operatorname{Pr}(A \\cap B) & = & \\operatorname{Pr}(A \\mid B)\\,\\operatorname{Pr}(B) \\\\\n",
    "        & = & \\operatorname{Pr}(B \\mid A)\\,\\operatorname{Pr}(A)\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Using this symmetry to solve for one of the two conditional probabilities yields **Bayes' rule**:\n",
    "\n",
    "$$ \\operatorname{Pr}(A \\mid B) = \\frac{\\operatorname{Pr}(B \\mid A)\\,\\operatorname{Pr}(A)}{\\operatorname{Pr}(B)} $$\n",
    "\n",
    "In the context of **Bayesian inference**, we usually consider $A$ as being the event corresponding to \"some fact is true about the world\", and $B$ as being the event corresponding to \"we observed some set of data\". In this case,\n",
    "* $\\operatorname{Pr}(A)$ corresponds to our **prior belief** that $A$ is true\n",
    "* $\\operatorname{Pr}(A \\mid B)$ is the updated **posterior belief** about $A$, given that we observed $B$\n",
    "* $\\operatorname{Pr}(B \\mid A)$ is the **likelihood** of observing $B$ assuming that $A$ is true\n",
    "    * This is the topic of statistical modeling: a **model** corresponds to a specification of a probability distribution / likelihood for the data under assumptions about how the world works)\n",
    "* $\\operatorname{Pr}(B)$ is the **marginal** of the likelihood, integrated against all possible world-truths\n",
    "    * The math for these can be very gnarly in general (sometimes it's questionable whether they even *exist*), but thankfully it turns out that most of the time we can do inference without worrying about them at all, because they don't depend on $A$, the hypothesis about the world we want to know about"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0192471f-8717-4ece-88c4-e2566efd1ed8",
   "metadata": {},
   "source": [
    "### Law of total probability\n",
    "\n",
    "Given a sample space $\\Omega$, a collection of sets $A_1, A_2, \\ldots A_n$ is called a **partition** if\n",
    "\n",
    "1. $ \\bigcup_i A_i = \\Omega $ (That is, the $A_i$ **cover the sample space**.)\n",
    "2. For any $i \\neq j$, $A_i \\cap A_j = \\emptyset$ (That is, the $A_i$ **do not overlap with one another**.)\n",
    "\n",
    "This definition is made mathematically because it implies the following fact:\n",
    "\n",
    "* Every outcome $\\omega \\in \\Omega$ is in **exactly one** of the $A_i$\n",
    "    * Proof: The $A_i$ cover $\\Omega$, so $\\omega$ is in *at least* one $A_i$. If $\\omega$ was in two distinct sets $A_i$ and $A_j$, then that would mean that $\\omega \\in A_i \\cap A_j$; but, this cannot be the case, because $A_i$ and $A_j$ do not overlap.\n",
    "\n",
    "Sometimes it's difficult to compute the size $\\operatorname{Pr}$ of a set $C$. However, it can be easier to *build up* $C$ from component pieces in smaller parts of the sample space $A_1, A_2, \\ldots A_n$. If the smaller parts we're breaking up $C$ inside of form a *partition* of $\\Omega$, then we have that\n",
    "\n",
    "$$ \\operatorname{Pr}(C) = \\sum_i \\operatorname{Pr}(C \\cap A_i) $$\n",
    "\n",
    "This works because we don't miss any part of $C$ (because the $A_i$ cover the space) and we also don't double-count any part of $C$ (because the $A_i$ don't overlap). An even more convenient form comes when we note that each term can be written in terms of conditional probability:\n",
    "\n",
    "$$ \\operatorname{Pr}(C) = \\sum_i \\operatorname{Pr}(C \\mid A_i)\\,\\operatorname{Pr}(A_i) $$\n",
    "\n",
    "This works because $\\operatorname{Pr}(C \\cap A_i)$, the sie of the part of $C$ that is in $A_i$, can be thought of as the size of $C$ *relative to* $A_i$—i.e., $\\operatorname{Pr}(C \\mid A_i)$—*times* the overall size of $\\operatorname{Pr}(A_i)$.\n",
    "\n",
    "This latter form is the **law of total probability**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5fc2fc-08a2-4f63-95a1-4ebe12caedfa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cae6672-211c-4297-b5ff-5e0455cd82f3",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f7a41-4952-46b2-a7bc-4c841fe86a24",
   "metadata": {},
   "source": [
    "### Solving problems\n",
    "\n",
    "**The fundamental essence of math lies in breaking down big, hard problems into a bunch of small, easy problems**. For example, if someone asked me what is\n",
    "\n",
    "$$ \\sqrt{1764} $$\n",
    "\n",
    "I would say, “That’s hard. I don’t know how to do that just looking at the number.” But on the other hand,\n",
    "\n",
    "$$ \\sqrt{2^2 \\times 3^2 \\times 7^2} $$\n",
    "\n",
    "is doable: I know that square roots undo squaring, and that the square root of a product is the product of the square roots. So, the answer has to be $2 \\times 3 \\times 7 = 42$. The fact that $1764$ can be decomposed this way—and, that the \"square root\" operation respects the decomposition so nicely—makes solving this problem easier. This is the essence of mathematical **structure**.\n",
    "\n",
    "This tells us something very general about the way people represent knowledge. All concepts need to be broken down into smaller parts that are individually understandable—pieces that can then be assembled together to get the whole idea. That is to say, knowledge is fundamentally **compositional**. This is an essential law for math, which is at its core the study of structured thought. It underlies the ubiquity of the modern foundations of mathematics in [category theory](https://en.wikipedia.org/wiki/Category_theory), which has composability as its central, defining axiom.\n",
    "\n",
    "It also lies at the heart of how to write code. Large problems can be broken up into smaller problems, which are easier to solve on their own. These smaller solutions can then not only be assembled to form a solution to the larger problem, but can in fact be assembled together in *new* ways to solve *different* problems than were originally imagined. Before writing a single line of code, then, it is imperative to understand the **structure** of the problem—that is, how it can be broken down into its constituent parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a7dee-caef-4804-a5b9-238cb274636e",
   "metadata": {},
   "source": [
    "### Large-scale problem structure\n",
    "\n",
    "Looking at what we're asked to do for this problem, I immediately break down the general task as follows:\n",
    "\n",
    "* For each value of $n$:\n",
    "    * $n$ times over:\n",
    "        * we're going to run a simulation to get one realization of our 3-neuron setup\n",
    "    * After that, we're going to evaluate a few different metrics on that data\n",
    "* Then, for each problem 1a–1e:\n",
    "    * We make pretty plots of this metric as we vary $n$\n",
    "\n",
    "So the three fundamental parts of our problem are `simulate`, `evaluate`, and `plot`. The most critical parts for specifying these sub-problems are to understand their **inputs** and their **outputs**. In my mind, I view these as:\n",
    "\n",
    "* `simulate`\n",
    "    * *Inputs*: None.\n",
    "    * *Outputs*: Three binary decisions, of whether A, B, and C fired\n",
    "* `evaluate`\n",
    "    * *Inputs*: Three lists of $n$ binary decisions, specifying whether A, B, and C fired in each trial\n",
    "    * *Outputs*: Five numbers, corresponding to the metrics from 1a–1e\n",
    "* `plot`\n",
    "    * *Inputs*: A list of the $n$s, and a list of one of the metrics from `evaluate` across each simulated $n$\n",
    "    * *Outputs*: A pretty picture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9128911b-0583-4875-8137-4d2fab991594",
   "metadata": {},
   "source": [
    "### `simulate`\n",
    "\n",
    "To simulate this setup, let's write out our model. In this case, we have three random variables: $A$, $B$, and $C$, each of which takes values of either $0$ or $1$. $C$ and $A$ are dependent, and $C$ and $B$ are dependent, but $A$ and $B$ are independent; we can represent this visually by drawing *nodes* for $A$, $B$, and $C$, and then drawing *edges* between variables that have dependencies (between $A$ and $C$, and between $B$ and $C$). This is known as a **graphical model**.\n",
    "\n",
    "The graphical model gives us an indication of how we should do our simulation: if we figure out what's going on with $A$ and $B$, we then know all of the dependencies that determine $C$. Since we know how $A$ and $B$ behave, as well as the structure of $C$'s dependence on $A$ and $B$, from the definition of the problem, this is how we can proceed. At first glance, the structure of our problem is:\n",
    "\n",
    "* Simulate if $A$ fired, with probability $p_A$\n",
    "* Simulate if $B$ fired, with probability $p_B$\n",
    "* Determine the probability $q$ that $C$ fired, based on the conditional probabilities for $C$ given $A$ and $B$\n",
    "* Simulate if $C$ fired, with probability $q$\n",
    "* Return $(A, B, C)$\n",
    "\n",
    "Note that there is a **repeated task** here: determining whether something fired with a certain probability $p$. Whenever there is a repeated task, it is a good idea to encapsulate that task in a **function**. In this case, we might consider making a function like this:\n",
    "\n",
    "* `random_fire`\n",
    "    * *Inputs*: Probability of firing $p$\n",
    "    * *Outputs*: `True` if it fired, `False` if it didn't\n",
    "\n",
    "How would we implement this function? Well, `numpy.random.uniform()` returns a uniform random number between $0$ and $1$. Notice that the fraction of the time a uniform random number between $0$ and $1$ is less than $p$ is exactly $p$. So, we might do something like"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8011c6a4-79a4-4f4c-872b-2442021d94d9",
   "metadata": {},
   "source": [
    "def random_fire( p ):\n",
    "    if np.random.uniform() < p:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca2450c-3958-477c-a874-b1151b8185c4",
   "metadata": {},
   "source": [
    "Now our procedure is something like\n",
    "\n",
    "* $A$ = `random_fire(` $p_A$ `)`\n",
    "* $B$ = `random_fire(` $p_B$ `)`\n",
    "* Determine the probability $q$ that $C$ fired, based on the conditional probabilities for $C$ given $A$ and $B$\n",
    "* $C$ = `random_fire(` $q$ `)`\n",
    "* Return $(A, B, C)$\n",
    "\n",
    "All that's left is a table lookup for the conditional probabilities, and we're done!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec695ae-ec8c-4148-9ed0-d94a23919e44",
   "metadata": {},
   "source": [
    "### `evaluate`\n",
    "\n",
    "All five of the metrics involve conditional probability, so we should probably make a function that can compute that!\n",
    "\n",
    "* `pr`\n",
    "    * *Inputs*: `xs`, a list of binary values we want to know the probability of, and `where`, a list of binary values that specify what we want to condition on\n",
    "    * *Outputs*: $\\operatorname{Pr}(\\texttt{xs}\\mid\\texttt{where})$\n",
    "\n",
    "Once this is specified, we just need to appropriately determine `xs` and `where` for each of the problems we want to solve. Using `numpy` arrays, this is just a matter of judiciously using the `&` and `~` operators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35f208-e7f8-4e3c-a0f9-b1179502cf49",
   "metadata": {},
   "source": [
    "### `plot`\n",
    "\n",
    "This is unfortunately just a matter of knowing where to look in the `matplotlib` documentation.\n",
    "\n",
    "> **Protip**: If you make `plot` a function that takes a `matplotlib` axes object as an argument and then makes your plot into those axes, then you can re-use your plotting code inside of subplots you make elsewhere. Doesn't sound helpful now, but it'll make your life 19374838273x easier in practical programming problems!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be994d02-beb5-456d-bfd4-ed0ca03490c7",
   "metadata": {},
   "source": [
    "### Simulating random variables\n",
    "\n",
    "Any numerical distribution can be simulated by using the **inverse CDF method**:\n",
    "\n",
    "* `sim_inverse_cdf`\n",
    "    * *Input*: A cdf `F` of some distribution to simulate\n",
    "    * *Output*: A random variate distributed according to the cdf\n",
    "    * *Algorithm*:\n",
    "        * Take $U$ from a uniform distribution on $[0, 1]$\n",
    "        * Use interpolation to compute $V$ = `F`$^{-1}(U)$\n",
    "        * Return $V$\n",
    "        \n",
    "Note that what we did above to simulate a binary random variable with a certain probability $p$ is just a reduced version of this algorithm: if `F` is the cdf for this variable, then `F` starts at zero, jumps up to $p$ at $x = 0$, and then jumps up to 1 at $x = 1$. The inverse of `F` is then $0$ if $U$ is less than $p$, and $1$ otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e574c448-7a01-4981-9850-613d54f57674",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e19c6-0044-4cac-bbb2-6cf1b1c7fae1",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d776548-c327-49fc-92f9-d421df1dad87",
   "metadata": {},
   "source": [
    "### Large-scale problem structure\n",
    "\n",
    "Here's how I broke up this problem:\n",
    "\n",
    "#### 3a–b\n",
    "Solution is `load_csv` $\\to$ `histogram` $\\to$ `plot_histogram`, where\n",
    "* `load_csv`\n",
    "    * *Inputs*: A path to where the data is stored in `.csv` format\n",
    "    * *Outputs*: An array containing the data loaded in from the input file\n",
    "    * *Note*: This is already implemented as, e.g., `pandas.read_csv`\n",
    "* `histogram`\n",
    "    * *Inputs*: An array of data, and the bin edges we want to use\n",
    "    * *Outputs*: The number of data points in each bin\n",
    "    * *Note*: This is already implemented as `numpy.histogram`\n",
    "* `plot_histogram`\n",
    "    * *Inputs*: A histogram\n",
    "    * *Outputs*: A pretty picture\n",
    "\n",
    "#### 3c\n",
    "Solution is\n",
    "* `load_csv` $\\to$\n",
    "    * `histogram` $\\to$ `pmf` $\\to$ `plot_pmf`, plus\n",
    "    * `cdf` $\\to$ `plot_cdf`\n",
    "\n",
    "where:\n",
    "* `pmf`\n",
    "    * *Inputs*: The histogram (i.e., count in each bin)\n",
    "    * *Outputs*: The empirical pmf (i.e., the histogram normalized to sum to 1)\n",
    "* `cdf`\n",
    "    * *Inputs*: An array of `data`, and an array `xs` of points at which to evaluate the cdf\n",
    "    * *Outputs*: An array with, for each `x` in `xs`, the fraction of `data` $\\leq$ `x`\n",
    "* `plot_pmf`, `plot_cdf`\n",
    "    * *Inputs*: Respective objects\n",
    "    * *Ouptuts*: Respective pretty pictures\n",
    "\n",
    "#### 3d–e\n",
    "Solution is `load_csv` $\\to$ `histogram` $\\to$ `pmf` $\\to$ `bayes` $\\to$ `estimator`, where\n",
    "* `bayes`\n",
    "    * *Inputs*: The empirical pmf over spike counts for each class, and the prior over classes\n",
    "    * *Outputs*: The posterior distribution over all spike counts for each class (just Bayes' rule)\n",
    "* `estimator`\n",
    "    * *Inputs*: The posteriors\n",
    "    * *Outputs*: A function that takes as input a spike count, and returns the posterior probability for each class (using either the nearest bin, or interpolation, or some other scheme)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328340bf-dbf3-417e-984e-7e44652dcb61",
   "metadata": {},
   "source": [
    "### Using standard interfaces\n",
    "\n",
    "The input-output structure of a function is called its **interface**. For a *class*, the interface is specified by the interfaces of the class' members (i.e., instance variables and methods).\n",
    "\n",
    "For example, in the Python machine learning field, models generally have the following interface:\n",
    "* `fit`\n",
    "    * *Input*: Training data for the model (e.g., `X`, the observed spike counts, and `y`, the stimulus labels)\n",
    "    * *Output*: None, but results in training the model\n",
    "* `predict`\n",
    "    * *Input*: Array of inputs from the model's input space (e.g., `X`, the observed spike counts)\n",
    "    * *Output*: The model's predicted outputs (e.g., the probabilities of each observation being in each stimulus class, or the maximum *a posteriori* class)\n",
    "    \n",
    "I have implemented this interface in the context of Problem 3 in the `ps1prob3.EmpiricalBayesClassifier` class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32732cb-e8a3-4c6a-b589-d46102691e1c",
   "metadata": {},
   "source": [
    "### The bias-variance tradeoff\n",
    "\n",
    "For the problem of determining the **maximum *a posteriori* class** based on count data, we first need to have some kind of **model** of how we believe the counts behave given each class. A natural first choice for this is the **Poisson distribution**, which is determined by one paramater—$\\lambda$, the average number of spikes. This distribution is what is known as **maximum entropy**—it \"imparts the least amount of constraint\" given that the counts have a particular average.\n",
    "\n",
    "There is another reason to use this as a good starting model, though: the **bias-variance tradeoff**. Remember that your model is actually *a function of your data* (because you use your data to fit your model). Since your data is random, that means your model is also random!\n",
    "\n",
    "This means that errors in your model can come from two places:\n",
    "* The space of models you're considering is far away from the truth because it's too small (*bias*)\n",
    "* The random noise in your training data makes you meander around your model space, making you pick a model that isn't very good (*variance*)\n",
    "\n",
    "You can think of your empirical data, then, as money: you can choose to spend some of that money either on having additional parameters (i.e., a bigger, more detailed model that is theoretically capable of getting close to the truth), or on being more certain about the parameters you already have (i.e., reducing the noise in your estimate of the model). A Poisson model has $1$ parameter ($\\lambda$), so you spend all your money on knowing that parameter really well. If, on the other hand, you use the raw empirical pmf across all possible counts, that has $\\sim 50$ parameters (one for each possible count value), and so you only can expend $1/50$ of the data on each parameter. That means that your precision in knowing each one of those parameters is very low—i.e., your model is subject to a lot of noise.\n",
    "\n",
    "Note the link between bias and variance: if we reduce bias by making the model class bigger, we increase variance because there is now more room in the space for noise to push us. It is a fundamental principle of statistical decision theory that there is no objective “best choice” of how many parameters to have: this is why it is the bias-variance **tradeoff**. However, the problem becomes solvable if we add additional constraints; this is generally imposed by using something like **cross-validation**, which allows us to empirically check how important it is for our application to have a more detailed model vs. a less noisy model.\n",
    "\n",
    "(A crude engineer’s rule of thumb is that for general regression problems, if you have less than 10 data points per parameter, you know you’re probably in the danger zone.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d957db2a-049a-47fb-a393-d0cb7007150d",
   "metadata": {},
   "source": [
    "### Optimal decoding\n",
    "\n",
    "At the end of this problem, we use a given number of spikes ($52$) to decide the posterior probability of the two stimuli. This is an example of **decoding**.\n",
    "\n",
    "Suppose your data are pairs of random variables $(O_i, L_i)$ where each $O \\in X$ is some observation from the set of possible observed values $X$ (e.g., number of spikes) and each $L \\in \\{1, 2, \\ldots n\\}$ is a label assigning one class (e.g., stimulus) to that observation. Then a function\n",
    "\n",
    "$$ f: X \\to \\{1, 2, \\ldots n\\} $$\n",
    "\n",
    "is called a **classifier**. If we know the distribution of class labels $\\operatorname{Pr}(L = k)$ and the conditional distributions of the observations for each class label $\\operatorname{Pr}(O = x \\mid L = k)$, then there is a \"best classifier\", which turns out to be precisely the one given by Bayes' rule. One can see this as a practical justification for using Bayes' rule: Bayes' rule is \"the rule that would give us the best possible classification accuracy\".\n",
    "\n",
    "This \"bestness\" is in the following sense. The set of *all* possible classifiers is denoted $(X \\to \\{1, 2, \\ldots n\\})$, i.e., the set of all such functions. A **value function** $V$ is a rule that assigns to each classifier a number specifying how \"good\" that classifier is; that is,\n",
    "\n",
    "$$ V: (X \\to \\{1, 2, \\ldots n\\}) \\to \\mathbb{R} $$\n",
    "\n",
    "Let's consider one such valuation function, the **empirical accuracy**:\n",
    "\n",
    "$$ V_\\textrm{accuracy}: f \\mapsto \\sum_i I(f(O_i) = L_i) $$\n",
    "\n",
    "Where $I$ is the \"indicator variable\", which is defined to be $1$ when its argument is true and $0$ otherwise. (This, in symbols, is saying that $V_\\textrm{accuracy}$ is *the number of times the classifier makes the correct choice on the observed data $(O_i, L_i)$*.)\n",
    "\n",
    "An **empirically optimal classifier** is a classifier $f^\\ast$ such that\n",
    "\n",
    "$$ f^\\ast = \\underset{f: X \\to \\{1, 2, \\ldots n\\}}{\\operatorname{argmax}} V_\\textrm{accuracy}(f) $$\n",
    "\n",
    "(This, in symbols, is saying that $f^\\ast$ is, amongst all possible **arguments**, or classifiers, $f$, the one that **maximizes** the empirical accuracy $V_\\textrm{accuracy}(f)$.)\n",
    "\n",
    "Then:\n",
    "\n",
    "> **[Theorem](https://en.wikipedia.org/wiki/Bayes_classifier)**: The unique empirically optimal classifier $f^\\ast$ is given by the **maximum *a posteriori* (MAP) classifier**:\n",
    ">\n",
    "> $$\n",
    "\\begin{eqnarray*}\n",
    "    f^\\ast(x) & = & \\underset{k}{\\operatorname{argmax}} \\operatorname{Pr}(L = k \\mid O = x) \\\\\n",
    "        & = & \\underset{k}{\\operatorname{argmax}} \\operatorname{Pr}(O = x \\mid L = k)\\,\\operatorname{Pr}(L = k)\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "*N.B.*: This classifier is not possible to obtain in practice, because it requires knowing the true distribution of the data, which we don't ever have. However, many methods—for example, **Naïve Bayes**—attempt to approximate it by making certain assumptions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
